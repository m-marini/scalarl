---
version: "4"
env:
  type: LanderTiles
  actionConfig: ContinuousActions
  dt: 0.25
  h0Range: 5
  z0: 1
  fuel: 10
  zMax: 150
  hRange: 500
  zRange: 150
  vhRange: 24
  vzRange: 12
  landingRadius: 10
  #landingVH: 0.5
  landingVH: 4
  landingVZ: 4
  g: 1.6
  maxAH: 1
  maxAZ: 3.2
  landedReward: 10
  crashReward: -10
  outOfRangeReward: -10
  outOfFuelReward: -10
  rewardDistanceScale: 0
  flyingReward: -1
agent:
  type: ActorCritic
  avgReward: 0
  rewardDecay: 0.99
  valueDecay: 0.99
  planner:
    planningSteps: 5
    minModelSize: 30
    maxModelSize: 200
    threshold: 0.1
    stateKey:
      type: Binary
    actionsKey:
      type: Tiles
      offset: [0, 0, 0]
      max: [5, 5, 5]
      tiles: [100, 100, 100]
    #modelPath: lander-model
  network:
    numHiddens:
      - 30
      - 30
    shortcuts:
      - [ 0, 3 ]
    seed: 1234
    updater: Adam
    learningRate: 3e-3
    beta1: 0.9
    beta2: 0.999
    epsilonAdam: 0.1
    maxAbsGradients: 1
    maxAbsParameters: 10e3
    dropOut: 0.8
  actors:
    - type: GaussianActor
      alphaMu: 10e-3
      alphaSigma: 10e-3
      muRange: [-1, 6]
      sigmaRange: 10
    - type: GaussianActor
      alphaMu: 10e-3
      alphaSigma: 10e-3
      muRange: [-1, 6]
      sigmaRange: 10
    - type: GaussianActor
      alphaMu: 10e-3
      alphaSigma: 10e-3
      muRange: [-1, 6]
      sigmaRange: 10
session:
  numSteps: 1000
  seed: 1234
  #trace: debug/lander-trace.csv
  dump: debug/lander-dump.csv
  #modelFile: debug/lander-model
  kpiFile: debug/kpi.csv
